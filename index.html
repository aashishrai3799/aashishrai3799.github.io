<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<html>

<head>
  
  <meta name=viewport content="width=800">
  <meta name="generator" content="HTML Tidy for Linux/x86 (vers 11 February 2007), see www.w3.org">
  <style type="text/css">
    /* Color scheme stolen from Sergey Karayev */

    a {
      color: #1772d0;
      text-decoration: none;
    }

    a:focus,
    a:hover {
      color: #f09220;
      text-decoration: none;
    }

    body,
    td,
    th,
    tr,
    p,
    a {
      font-family: 'Titillium Web', Verdana, Helvetica, sans-serif;
      font-size: 16px;
      font-weight: 400
    }

    strong {
      font-family: 'Titillium Web', Verdana, Helvetica, sans-serif;
      font-size: 16px;
      font-weight: 600
    }

    heading {
      font-family: 'Titillium Web', Verdana, Helvetica, sans-serif;
      font-size: 17px;
      font-weight: 600
    }

    papertitle {
      font-family: 'Titillium Web', Verdana, Helvetica, sans-serif;
      font-size: 16px;
      font-weight: 600
    }

    name {
      font-family: 'Titillium Web', Verdana, Helvetica, sans-serif;
      font-size: 32px;
      font-weight: 500
    }

    .one {
      width: 160px;
      height: 160px;
      position: relative;
    }

    .two {
      width: 160px;
      height: 160px;
      position: absolute;
      transition: opacity .2s ease-in-out;
      -moz-transition: opacity .2s ease-in-out;
      -webkit-transition: opacity .2s ease-in-out;
    }

    .fade {
      transition: opacity .2s ease-in-out;
      -moz-transition: opacity .2s ease-in-out;
      -webkit-transition: opacity .2s ease-in-out;
    }

    span.highlight {
      background-color: #ffffd0;
    }
  </style>
  <link rel="icon" type="image/png" href="images/ri_logo.png">
  <title>Aashish Rai</title>
  <meta http-equiv="Content-Type" content="text/html; charset=us-ascii">
  <!-- <link href='https://fonts.googleapis.com/css?family=Lato:400,700,400italic,700italic' rel='stylesheet' type='text/css'> -->
  <link href="https://fonts.googleapis.com/css?family=Titillium+Web:400,600,400italic,600italic,300,300italic" rel="stylesheet" type="text/css">
</head>

<body>
  <table width="1024" border="0" align="center" cellspacing="0" cellpadding="0">
    <tr>
      <td>
        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
          <tr>
            <td width="67%" valign="middle">
              <p align="center">
                <name>Aashish Rai</name>
              </p>
              <p align="justify">I am a full-time Research Assistant at <a href="https://www.ri.cmu.edu/">Robotics Institute</a>, <a href="https://www.cmu.edu/">Carnegie Mellon University</a>, advised by <a href="https://www.cs.cmu.edu/~ftorre/">Fernando De la Torre</a> at <a href="http://humansensing.cs.cmu.edu/home">Human Sensing Lab</a>.
                Currently, I'm working on a project for "3D Face Generation with granular control over expressions" in part with Facebook/Meta. 
                
                </p>

                <p align="justify"> Prior to CMU, I did my undergrad at National Institute of Technology<a href="https://www.svnit.ac.in"> (NIT) Surat</a> in Electronics and Communication Engineering, where I worked with <a href="https://scholar.google.com/citations?hl=en&user=6C287fwAAAAJ&view_op=list_works&sortby=pubdate">Kishor Upla</a> on problems in Deep Learning and Computer Vision. During my undergrad, I had the opportunity to work/collaborate with <a href="http://srl.mcgill.ca/">McGill University</a>, <a href="https://www.ntnu.edu/nbl#/view/about">Norwegian Biometrics Lab</a>, and <a href="https://www.iirs.gov.in/">Indian Space Research Organization (ISRO)</a> on Computer Vision research.
              </p>


              <p> I'm always open to research opportunities in this area. Feel free to contact me via email.</p>


              <p align=center>
                <a href="mailto:aashishr@andrew.cmu.edu">Email</a> &nbsp/&nbsp
                <!-- <a href="data/myCV.pdf">CV</a> &nbsp/&nbsp -->
                <a href="https://scholar.google.com/citations?hl=en&user=RxaDP08AAAAJ&view_op=list_works&sortby=pubdate">Google Scholar</a> &nbsp/&nbsp
                <!-- <a href="https://twitter.com/shikharbahl"> Twitter </a> &nbsp/&nbsp -->
                <a href="https://github.com/aashishrai3799">GitHub</a> &nbsp/&nbsp
                <a href="https://www.linkedin.com/in/aashishrai3799">LinkedIn</a>
              </p>
            </td>
            <td width="33%">
              <img src="images/aashish.png" width="200"  height="250" style="border-style: none">
            </td>
          </tr>
        </table>
        
        
        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
          <tr>
            <td width="100%" valign="middle">
              <heading>RESEARCH EXPERIENCE</heading>
              <p align="justify">
                I've worked on diverse projects in Human Faces, including controllable 3D face generation, face recognition in an unconstrained environment, computationally efficient super-resolution, and face manipulation using generative networks. Other than the faces, I've also experienced working with satellite image classification, objects and scene understanding.
              </p>
            </td>
          </tr>
        </table>

        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">

          <tr>
            <td width="25%" align="center"><img src="images/ri_logo.png" width="90"  height="125" style="border-style: none">
              <td width="75%" valign="top">
                <p align="justify">
                <strong> Research Assistant <br> Robotics Institute, Carnegie Mellon University </strong> <br>
								Pittsburgh, PA, USA <br>

								(Sept/2021 - May/2023) <br>
								Working on 3D generative models for face that decouples identity and expression, and provides granular control over them. <br>
								
			 					Advisor: <a href="http://www.cs.cmu.edu/~ftorre/index.html"">Fernando De la Torre</a>
                </p>
              </td>
          </tr>



          <tr>
            <td width="25%" align="center"><img src="images/mcgill.png" width="250"  height="125" style="border-style: none">
              <td width="75%" valign="top">
                <p align="justify">
                <strong> Research Intern <br> Shared Reality Lab, McGill University </strong> <br>
								Montreal, Canada <br>
								(May/2020 - Mar/2021) <br>
			 					- Worked on improving Semantic Face Editing (control any specific face attribute keeping others unaltered) of StyleGAN2 outputs in terms of perceived quality of facial features. <br> 
			 					
								- Modified the framework to make it equally usable for various other complex attributes like race, face shape, etc. <br> 
			 					Advisor: <a href="http://www.cim.mcgill.ca/~jer/"">Jeremy Cooperstock</a>
                </p>
              </td>
          </tr>
          
          
          
         <tr>
            <td width="25%" align="center"><img src="images/ntnu.png" width="130"  height="150" style="border-style: none">
              <td width="75%" valign="top">
                <p align="justify">
                <strong> Undergraduate Researcher <br> Norwegian Biometrics Laboratory, NTNU Norway </strong> <br>
								
								(Dec/2019 - May/2020) <br>
			 					- Designed a CNN based, light weight, progressive residual propagating asymmetrical architecture with three modules (LF, HF feature extraction and reconstruction) to generate 8x upscaled (Super Resolution) images from 8x8, 16x16, 24x24 LR images. <br> 
			 					
 								- The model gave appreciable results on benchmark datasets CelebA (PSNR: 26.55) and LFW (PSNR: 26.26). <br> 
			 					Advisor: <a href="https://scholar.google.com/citations?hl=en&user=6C287fwAAAAJ&view_op=list_works&sortby=pubdate"">Kishor Upla</a>, 
			 					<a href="https://www.christoph-busch.de/"">Christoph Busch</a>
                </p>
              </td>
          </tr>
          
          
          
          
         <tr>
            <td width="25%" align="center"><img src="images/iirs_isro.png" width="125"  height="125" style="border-style: none">
              <td width="75%" valign="top">
                <p>
                <strong> Summer Research Intern <br> IIRS, Indian Space Research Organization (ISRO) </strong> <br>
								Dehradun, India <br>
								(May/2019 - Jul/2019) <br>
			 					- Implemented computationally efficient algorithms for the pixel-wise classification of Panchromatic (single band) and Multispectral (up-to 15 bands) satellite images using ANN and CNN. <br> 
			 					Advisor: <a href="https://www.iirs.gov.in/Anil-profile"">Anil Kumar</a>
                </p>
              </td>
          </tr>
          
          
          
         <tr>
            <td width="25%" align="center"><img src="images/svnit.png" width="125"  height="125" style="border-style: none">
              <td width="75%" valign="top">
                <p>
                <strong> Undergraduate Researcher <br> MLCV Lab, NIT Surat </strong> <br>
								Surat, India <br>
								(Jan/2019 - Nov/2019) <br>
			 					- Designed an Automated Attendance System using Deep Learning to mark the attendance of entire class simultaneously and overcome usual challenges of occlusion, orientation and luminance. <br> 
			 					Advisor: <a href="https://scholar.google.com/citations?hl=en&user=6C287fwAAAAJ&view_op=list_works&sortby=pubdate"">Kishor Upla</a>
                </p>
              </td>
          </tr>
          

        </table>
        
        
        
        
        
        
        
        
      
      <br>
      <br>
      <br>
      
      
      
      
      
      
      
      
      
      
      
        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
          <tr>
            <td width="100%" valign="middle">
              <heading>RESEARCH PAPERS/CHAPTERS</heading>
            </td>
          </tr>
        </table>

        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">

      
         <tr>
            <td width="25%"><img src="images/3dfacecam.gif" width="200" height="140" style="border-style: none">
              <td width="75%" valign="top">
                <p>
                  <!-- <a href="https://ieeexplore.ieee.org/document/9680017"> -->
                    <papertitle>Controllable 3D Generative Adversarial Face Model via Disentangling Shape and Appearance</papertitle>
                  <!-- </a> -->
                  <br>
                  <a href="https://ulteraa.github.io/Fariborz.github.io/">Fariborz Taherkhani</a>, <strong>Aashish Rai</strong>, <a href="https://zerg-overmind.github.io/">Quankai Gao</a>, <a href="hhttps://shaunak99.github.io/profilev2/">Shaunak Srivastava</a>, Xuanbai Chen, <a href="https://www.cs.cmu.edu/~ftorre/">Fernando de la Torre</a>, Steven Song</a>, <a href="https://aayushp.github.io/">Aayush Prakash</a>, Daeil Kim
                  <br>
                  <em> arxiv, August-2022 </em>
                  <br>
                  <a href="https://aashishrai3799.github.io/3DFaceCAM/">project page</a> | <a href="https://aashishrai3799.github.io/3DFaceCAM/">pdf</a>
                </p>

              </td>
          </tr>
      
      
      
         <tr>
            <td width="25%"><img src="images/mcgill_proj.png" width="200" height="140" style="border-style: none">
              <td width="75%" valign="top">
                <p>
                  <a href="https://ieeexplore.ieee.org/document/9680017">
                    <papertitle>Improved Attribute Manipulation in the Latent Space of StyleGAN for Semantic Face Editing</papertitle>
                  </a>
                  <br>
                  <strong>Aashish Rai</strong>, Clara Ducher, <a href="http://www.cim.mcgill.ca/~jer/">Jeremy Cooperstock</a>
                  <br>
                  <em> 20th IEEE International Conference on Machine Learning and Applications, Pasadena, CA, USA,</em> 2021
                  <br>
                  <a href="https://ieeexplore.ieee.org/document/9680017">pdf</a> | project page
                </p>

              </td>
          </tr>
          
          
          <tr>
            <td width="25%"><img src="images/mcgill_proj.png" width="200" height="140" style="border-style: none">
              <td width="75%" valign="top">
                <p> <strong> [Chapter 4] </strong>
                  <a href="http://srl.mcgill.ca/publications/thesis/2021-MASTER-Ducher.pdf">
                    <papertitle>GAN-based interaction paradigms for photorealistic avatar creation.</papertitle>
                  </a>
                  <br>
                  <em> Clara Ducher, Master's thesis, McGill
University, Department of Electrical and Computer Engineering, Montreal, Canada,</em> 2021
                  <br>
                  <a href="http://srl.mcgill.ca/publications/thesis/2021-MASTER-Ducher.pdf">pdf</a>
                </p>

              </td>
          </tr>
          
          
          
          <tr>
            <td width="25%"><img src="images/comsupresnet.png" width="200" height="150" style="border-style: none">
              <td width="75%" valign="top">
                <p>
                  <a href="https://ieeexplore.ieee.org/document/9107946">
                    <papertitle>ComSupResNet: A Compact Super-Resolution Network for Low-Resolution Face Images.</papertitle>
                  </a>
                  <br>
                  <strong>Aashish Rai</strong>, Vishal Chudasama, Kishor Upla, Kiran Raja, Raghavendra Ramachandra, Christoph Busch
                  <br>
                  <em> 8th International Workshop on Biometrics and Forensics (IWBF), Porto, Portugal,</em> 2020
                  <br>
                  <a href="https://ieeexplore.ieee.org/document/9107946">pdf</a> | project page <br>
                  
                  (extended version is accepted in IEEE Transactions on Biometrics, Behavior and Identity Science (T-BIOM))
                </p>

              </td>
          </tr>
          
          
          
          <tr>
            <td width="25%"><img src="images/attendance.png" width="200" height="140" style="border-style: none">
              <td width="75%" valign="top">
                <p>
                  <a href="https://ieeexplore.ieee.org/document/9029001">
                    <papertitle>An End-to-End Real-Time Face Identification and Attendance System using Convolutional Neural Networks.</papertitle>
                  </a>
                  <br>
                  <strong>Aashish Rai</strong>, , R. Karnani, V. Chudasama and K. Upla
                  <br>
                  <em> 16th IEEE India Council International Conference (INDICON), Rajkot, India,</em> 2019
                  <br>
                  <a href="https://ieeexplore.ieee.org/document/9029001">pdf</a> | <a href="https://github.com/aashishrai3799/Automated-Attendance-System-using-CNN">project page</a>
                </p>

              </td>
          </tr>
          
          
        </table>
        
        

        
        
        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
          <tr>
            <td>
              <br>
              <p align="right">
                <font size="2">
                    (website template modified from <a href="https://github.com/jonbarron/jonbarron_website"> repo </a>)
                  </font>
              </p>
              
              <p align="center">
              <!--<script type="text/javascript" src="https://www.freevisitorcounters.com/en/home/counter/739523/t/3"></script> -->
              </p>
              
            </td>
          </tr>
        </table>
        </td>
    </tr>
  </table>
</body>

</html>
